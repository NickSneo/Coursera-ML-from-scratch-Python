{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with Backpropagation\n",
    "---\n",
    "This exercise implements a feed forward neural network with backpropagation from scratch. MNIST dataset is used. The input layer has 401 neurons corresponding to the 20x20 image (400 pixels + 1 bias). The hidden layer has 26 neurons (25 + 1 bias). The output layer has 10 neurons corresponding to the 0-9 digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoidal activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x,deriv=False):\n",
    "\tif deriv is True:\n",
    "\t\treturn x*(1-x)\n",
    "\treturn 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method to evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(A2, y):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(A2.shape[0]):\n",
    "\t\tresult = np.argmax(A2[i])\n",
    "\t\tresult+=1\n",
    "\n",
    "\t\tif result==0:\n",
    "\t\t\tresult=10\n",
    "\n",
    "\t\tactual = np.argmax(y[i])\n",
    "\t\tactual+=1\n",
    "\n",
    "\t\tif actual==0:\n",
    "\t\t\tactual=10\n",
    "\n",
    "\t\tif result==actual:\n",
    "\t\t\tcorrect+=1\n",
    "\n",
    "\t\t#print(\"Predicted:\" + str(result) + \" Actual:\" + str(y[i]))\n",
    "\n",
    "\tacc = (correct/5000)*100\n",
    "\treturn acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y,A):\n",
    "\tcost = y*np.log(A) + (1-y)*np.log(1-A)\n",
    "\treturn np.sum(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('ex4data1.mat')\n",
    "\n",
    "X = np.array(data['X'])\n",
    "y = np.array(data['y'])\n",
    "y = y.reshape(y.shape[0],1)\n",
    "\n",
    "X = np.insert(X, 0, np.ones(X.shape[0]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Initialization of weight matrices to break symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "episolon_init = 0.12\n",
    "w0 = np.random.random((401,26))*2*episolon_init - episolon_init\n",
    "w1 = np.random.random((26,10))*2*episolon_init - episolon_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "iters = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying dataset for One-vs-Rest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.zeros([y.shape[0],10])\n",
    "for i in range(y.shape[0]):\n",
    "\ttemp[i][y[i]-1] = 1\n",
    "\n",
    "y = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: -35861.91575529514\n",
      "Epoch 300: -4354.6332446959295\n",
      "Epoch 600: -2650.3834673949477\n",
      "Epoch 900: -2129.9577118279844\n",
      "Epoch 1200: -1823.4065436394221\n",
      "Training Accuracy:96.26\n"
     ]
    }
   ],
   "source": [
    "for i in range(iters):\n",
    "    #Forward propagation\n",
    "\tz0 = np.dot(X,w0)\n",
    "\tA0 = sigmoid(z0)\n",
    "\n",
    "\tz1 = np.dot(A0,w1)\n",
    "\tA1 = sigmoid(z1)\n",
    "\n",
    "\tA1_error = A1-y\n",
    "\n",
    "    #Backward propagation\n",
    "\tw1 = w1 - ( (alpha/len(X)) * ( np.dot(A0.T, A1_error) ) )\n",
    "\n",
    "\tA2_error = np.dot(A1_error,w1.T)\n",
    "\tA2_delta = A2_error * (sigmoid(A0,deriv=True))\n",
    "\n",
    "\tw0 = w0 - ( (alpha/len(X)) * ( np.dot(X.T, A2_delta) ) )\n",
    "\n",
    "\tif i%300==0:\n",
    "\t\tprint(\"Epoch \" + str(i) + \": \" + str(cost(y,A1)))\n",
    "\n",
    "print(\"Training Accuracy:\" + str(accuracy(A1,y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
